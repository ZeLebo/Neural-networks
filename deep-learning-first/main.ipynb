{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some preparations before we begin (or begging...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset CIFAR10\n",
       "     Number of datapoints: 50000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " <torch.utils.data.dataloader.DataLoader at 0x200bd5f9db0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, labels = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        images.append(item[0])\n",
    "        labels.append(item[1])\n",
    "    images = np.stack(images)\n",
    "    images = torch.from_numpy(images).float()\n",
    "    labels = torch.tensor(labels)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# some config vars\n",
    "batch_size = 32 * 2\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "learning_rate = 0.0001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# sample data\n",
    "need_download = not os.path.exists('data')\n",
    "train = torchvision.datasets.CIFAR10(root='data', train=True, download=need_download, transform=ToTensor())\n",
    "dataset = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test = torchvision.datasets.CIFAR10(root='data', train=False, download=need_download, transform=ToTensor())\n",
    "dataset_test = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "(train, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function for training and calculating loss\n",
    "def basic_training(model, allow_print=True) -> nn.Module:\n",
    "    if allow_print:\n",
    "        print(f\"{model.__class__.__name__} is training\")\n",
    "\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in dataset:\n",
    "            data, target = batch\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            opt.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        if allow_print:\n",
    "            print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "        \n",
    "    if allow_print:\n",
    "        print(\"Training done\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the accuracy on the random data from the dataset\n",
    "def test_model(model):\n",
    "    model.to(device)\n",
    "\n",
    "    # test the model on data form dataset_test\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataset_test:\n",
    "            data, target = batch\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    print(f\"Accuracy: {100 * correct / total}% {correct}/{total}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with only fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseModel is training\n",
      "Epoch: 0, Loss: 1.8294130563735962\n",
      "Epoch: 1, Loss: 1.9834905862808228\n",
      "Epoch: 2, Loss: 1.406627893447876\n",
      "Epoch: 3, Loss: 1.7146100997924805\n",
      "Epoch: 4, Loss: 1.5480809211730957\n",
      "Epoch: 5, Loss: 1.71500563621521\n",
      "Epoch: 6, Loss: 1.4947694540023804\n",
      "Epoch: 7, Loss: 1.498091220855713\n",
      "Epoch: 8, Loss: 1.964679479598999\n",
      "Epoch: 9, Loss: 1.5170519351959229\n",
      "Epoch: 10, Loss: 1.048494577407837\n",
      "Epoch: 11, Loss: 1.5307738780975342\n",
      "Epoch: 12, Loss: 1.4406089782714844\n",
      "Epoch: 13, Loss: 1.601004719734192\n",
      "Epoch: 14, Loss: 1.5936388969421387\n",
      "Epoch: 15, Loss: 1.5161917209625244\n",
      "Epoch: 16, Loss: 1.7282209396362305\n",
      "Epoch: 17, Loss: 1.9453601837158203\n",
      "Epoch: 18, Loss: 1.2604072093963623\n",
      "Epoch: 19, Loss: 1.4299336671829224\n",
      "Epoch: 20, Loss: 1.9541850090026855\n",
      "Epoch: 21, Loss: 1.5568022727966309\n",
      "Epoch: 22, Loss: 1.186700701713562\n",
      "Epoch: 23, Loss: 1.5579442977905273\n",
      "Epoch: 24, Loss: 0.9613252282142639\n",
      "Epoch: 25, Loss: 1.2199445962905884\n",
      "Epoch: 26, Loss: 1.0897176265716553\n",
      "Epoch: 27, Loss: 1.4703646898269653\n",
      "Epoch: 28, Loss: 1.221041202545166\n",
      "Epoch: 29, Loss: 1.42379891872406\n",
      "Epoch: 30, Loss: 1.2023487091064453\n",
      "Epoch: 31, Loss: 1.366619348526001\n",
      "Epoch: 32, Loss: 0.8809918761253357\n",
      "Epoch: 33, Loss: 1.0375566482543945\n",
      "Epoch: 34, Loss: 1.1979196071624756\n",
      "Epoch: 35, Loss: 1.4464088678359985\n",
      "Epoch: 36, Loss: 1.199257254600525\n",
      "Epoch: 37, Loss: 0.9330946207046509\n",
      "Epoch: 38, Loss: 1.350751280784607\n",
      "Epoch: 39, Loss: 1.157321810722351\n",
      "Epoch: 40, Loss: 1.2562843561172485\n",
      "Epoch: 41, Loss: 1.1511679887771606\n",
      "Epoch: 42, Loss: 1.4124951362609863\n",
      "Epoch: 43, Loss: 1.214669942855835\n",
      "Epoch: 44, Loss: 1.1275172233581543\n",
      "Epoch: 45, Loss: 1.051236867904663\n",
      "Epoch: 46, Loss: 0.8876473903656006\n",
      "Epoch: 47, Loss: 1.177242398262024\n",
      "Epoch: 48, Loss: 1.10736083984375\n",
      "Epoch: 49, Loss: 1.1361165046691895\n",
      "Training done\n",
      "Accuracy: 52.14% 5214/10000\n"
     ]
    }
   ],
   "source": [
    "# make a model only with fully connected layers\n",
    "class DenseModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseModel, self).__init__()\n",
    "\n",
    "        # that piece of crap almost ruined my day\n",
    "        IMG_SIZE = 32 * 32 * 3\n",
    "\n",
    "        self.fc1 = nn.Linear(IMG_SIZE, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = DenseModel()\n",
    "# model\n",
    "model = basic_training(model)\n",
    "test_model(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = ModelConvolutionalLayers()\\nbasic_training(model)\\ntest_model(model)\\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding convolutional layers to the model\n",
    "class ModelConvolutionalLayers(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelConvolutionalLayers, self).__init__()\n",
    "\n",
    "        # if I write it with my hands, it doen't work, but when whappening in sequential, it works\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(4 * 4 * 128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\"\"\"\n",
    "model = ModelConvolutionalLayers()\n",
    "basic_training(model)\n",
    "test_model(model)\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing different number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelSmallAmountLayers is training\n",
      "accuracy of model with only 1 layer\n",
      "Accuracy: 28.84% 2884/10000\n",
      "ModelFullyConnected is training\n",
      "accuracy of model with fully connected layers\n",
      "Accuracy: 33.62% 3362/10000\n"
     ]
    }
   ],
   "source": [
    "# model with only 1 layer\n",
    "class ModelSmallAmountLayers(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelSmallAmountLayers, self).__init__()\n",
    "\n",
    "        self.fc = nn.Linear(32 * 32 * 3, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\"\"\"\n",
    "model = ModelSmallAmountLayers()\n",
    "print(\"ModelSmallAmountLayers is training\")\n",
    "basic_training(model, allow_print=False)\n",
    "print(\"accuracy of model with only 1 layer\")\n",
    "test_model(model)\n",
    "\n",
    "model = ModelFullyConnected()\n",
    "print(\"ModelFullyConnected is training\")\n",
    "basic_training(model, allow_print=False)\n",
    "print(\"accuracy of model with fully connected layers\")\n",
    "test_model(model)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretend that ModelConvolutionalLayers in model with big amount of layers and compare them together\n",
    "as we can see from the output the model with only 1 layer is shifting much more than the model with 4 layers\n",
    "also we can see that the accuracy of such model is lower\n",
    "\n",
    "to be shorter, the more layers neural network has, the more complex objects it can detect, but the time (or resurses) for it's \n",
    "training would be increased"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelDropout is training\n",
      "Epoch: 0, Loss: 2.199138879776001\n",
      "Epoch: 1, Loss: 2.0977420806884766\n",
      "Epoch: 2, Loss: 1.4756028652191162\n",
      "Epoch: 3, Loss: 1.3236998319625854\n",
      "Epoch: 4, Loss: 2.085686445236206\n",
      "Epoch: 5, Loss: 1.5807256698608398\n",
      "Epoch: 6, Loss: 1.7575302124023438\n",
      "Epoch: 7, Loss: 1.5117683410644531\n",
      "Epoch: 8, Loss: 1.4893335103988647\n",
      "Epoch: 9, Loss: 1.7689285278320312\n",
      "Epoch: 10, Loss: 1.8285218477249146\n",
      "Epoch: 11, Loss: 1.6035689115524292\n",
      "Epoch: 12, Loss: 1.658751368522644\n",
      "Epoch: 13, Loss: 1.3808714151382446\n",
      "Epoch: 14, Loss: 1.8599021434783936\n",
      "Epoch: 15, Loss: 1.5263110399246216\n",
      "Epoch: 16, Loss: 1.829563856124878\n",
      "Epoch: 17, Loss: 1.935354471206665\n",
      "Epoch: 18, Loss: 1.7004787921905518\n",
      "Epoch: 19, Loss: 1.7640712261199951\n",
      "Training done\n",
      "Accuracy with dropout\n",
      "Accuracy: 57.07% 5707/10000\n",
      "ModelConvolutionalLayers is training\n",
      "Epoch: 0, Loss: 1.6173450946807861\n",
      "Epoch: 1, Loss: 1.3811346292495728\n",
      "Epoch: 2, Loss: 1.358305811882019\n",
      "Epoch: 3, Loss: 1.3055436611175537\n",
      "Epoch: 4, Loss: 1.3613412380218506\n",
      "Epoch: 5, Loss: 1.2089289426803589\n",
      "Epoch: 6, Loss: 1.337955355644226\n",
      "Epoch: 7, Loss: 1.2206746339797974\n",
      "Epoch: 8, Loss: 1.1535431146621704\n",
      "Epoch: 9, Loss: 1.2775297164916992\n",
      "Epoch: 10, Loss: 1.2461860179901123\n",
      "Epoch: 11, Loss: 1.1193068027496338\n",
      "Epoch: 12, Loss: 1.0678062438964844\n",
      "Epoch: 13, Loss: 1.3213382959365845\n",
      "Epoch: 14, Loss: 1.085822582244873\n",
      "Epoch: 15, Loss: 1.1566519737243652\n",
      "Epoch: 16, Loss: 1.1013792753219604\n",
      "Epoch: 17, Loss: 1.3299962282180786\n",
      "Epoch: 18, Loss: 1.1872140169143677\n",
      "Epoch: 19, Loss: 1.1281921863555908\n",
      "Training done\n",
      "Accuracy: 60.32% 6032/10000\n"
     ]
    }
   ],
   "source": [
    "# adding dropout layer\n",
    "\n",
    "global epochs\n",
    "epochs = 20\n",
    "\n",
    "class ModelDropout(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ModelDropout, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4 * 4 * 128, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "        \n",
    "\n",
    "model = ModelDropout()\n",
    "model = basic_training(model)\n",
    "print(\"Accuracy with dropout\")\n",
    "test_model(model)\n",
    "\n",
    "model = ModelConvolutionalLayers()\n",
    "model = basic_training(model)\n",
    "test_model(model)\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelDropout is training\n",
      "Epoch: 0, Loss: 3.0776095390319824\n",
      "Epoch: 1, Loss: 2.9820263385772705\n",
      "Epoch: 2, Loss: 2.7211365699768066\n",
      "Epoch: 3, Loss: 2.8907506465911865\n",
      "Epoch: 4, Loss: 2.7787039279937744\n",
      "Epoch: 5, Loss: 2.4318625926971436\n",
      "Epoch: 6, Loss: 2.7590668201446533\n",
      "Epoch: 7, Loss: 2.548741340637207\n",
      "Epoch: 8, Loss: 2.252854824066162\n",
      "Epoch: 9, Loss: 2.676725387573242\n",
      "Epoch: 10, Loss: 2.727212429046631\n",
      "Epoch: 11, Loss: 2.5998783111572266\n",
      "Epoch: 12, Loss: 2.324941873550415\n",
      "Epoch: 13, Loss: 2.4985804557800293\n",
      "Epoch: 14, Loss: 2.946016788482666\n",
      "Epoch: 15, Loss: 2.466244697570801\n",
      "Epoch: 16, Loss: 2.595196485519409\n",
      "Epoch: 17, Loss: 2.03120493888855\n",
      "Epoch: 18, Loss: 1.7425264120101929\n",
      "Epoch: 19, Loss: 1.8041839599609375\n",
      "Epoch: 20, Loss: 2.0775558948516846\n",
      "Epoch: 21, Loss: 1.7552191019058228\n",
      "Epoch: 22, Loss: 1.8387318849563599\n",
      "Epoch: 23, Loss: 1.946933388710022\n",
      "Epoch: 24, Loss: 2.024894952774048\n",
      "Epoch: 25, Loss: 2.22885799407959\n",
      "Epoch: 26, Loss: 2.2260210514068604\n",
      "Epoch: 27, Loss: 2.0261049270629883\n",
      "Epoch: 28, Loss: 2.0732178688049316\n",
      "Epoch: 29, Loss: 2.0702831745147705\n",
      "Epoch: 30, Loss: 2.1311779022216797\n",
      "Epoch: 31, Loss: 1.8353396654129028\n",
      "Epoch: 32, Loss: 2.0914411544799805\n",
      "Epoch: 33, Loss: 1.8847291469573975\n",
      "Epoch: 34, Loss: 1.4798479080200195\n",
      "Epoch: 35, Loss: 2.2574241161346436\n",
      "Epoch: 36, Loss: 1.9625509977340698\n",
      "Epoch: 37, Loss: 2.28364634513855\n",
      "Epoch: 38, Loss: 1.7791956663131714\n",
      "Epoch: 39, Loss: 2.2341179847717285\n",
      "Epoch: 40, Loss: 2.0886054039001465\n",
      "Epoch: 41, Loss: 1.7272448539733887\n",
      "Epoch: 42, Loss: 1.9263228178024292\n",
      "Epoch: 43, Loss: 1.9017826318740845\n",
      "Epoch: 44, Loss: 1.9753737449645996\n",
      "Epoch: 45, Loss: 1.8122402429580688\n",
      "Epoch: 46, Loss: 1.9410486221313477\n",
      "Epoch: 47, Loss: 1.9307715892791748\n",
      "Epoch: 48, Loss: 2.0618348121643066\n",
      "Epoch: 49, Loss: 1.6747245788574219\n",
      "Training done\n",
      "Accuracy: 51.76% 5176/10000\n",
      "ModelConvolutionalLayers is training\n",
      "Epoch: 0, Loss: 1.3931066989898682\n",
      "Epoch: 1, Loss: 1.3455090522766113\n",
      "Epoch: 2, Loss: 1.1239718198776245\n",
      "Epoch: 3, Loss: 1.3010238409042358\n",
      "Epoch: 4, Loss: 1.3247694969177246\n",
      "Epoch: 5, Loss: 1.3513169288635254\n",
      "Epoch: 6, Loss: 1.0996323823928833\n",
      "Epoch: 7, Loss: 1.0354151725769043\n",
      "Epoch: 8, Loss: 0.9224212169647217\n",
      "Epoch: 9, Loss: 1.2624529600143433\n",
      "Epoch: 10, Loss: 1.2609840631484985\n",
      "Epoch: 11, Loss: 1.5207371711730957\n",
      "Epoch: 12, Loss: 1.0999544858932495\n",
      "Epoch: 13, Loss: 1.1310580968856812\n",
      "Epoch: 14, Loss: 1.114914059638977\n",
      "Epoch: 15, Loss: 1.020563006401062\n",
      "Epoch: 16, Loss: 0.9555630683898926\n",
      "Epoch: 17, Loss: 1.1422063112258911\n",
      "Epoch: 18, Loss: 1.1578028202056885\n",
      "Epoch: 19, Loss: 1.248921513557434\n",
      "Epoch: 20, Loss: 1.2640652656555176\n",
      "Epoch: 21, Loss: 0.9388573169708252\n",
      "Epoch: 22, Loss: 1.2153065204620361\n",
      "Epoch: 23, Loss: 1.215019702911377\n",
      "Epoch: 24, Loss: 1.5407359600067139\n",
      "Epoch: 25, Loss: 1.1280406713485718\n",
      "Epoch: 26, Loss: 1.1626838445663452\n",
      "Epoch: 27, Loss: 1.1189197301864624\n",
      "Epoch: 28, Loss: 1.1800304651260376\n",
      "Epoch: 29, Loss: 1.0728883743286133\n",
      "Epoch: 30, Loss: 1.0649189949035645\n",
      "Epoch: 31, Loss: 1.2566288709640503\n",
      "Epoch: 32, Loss: 1.0168391466140747\n",
      "Epoch: 33, Loss: 1.0182762145996094\n",
      "Epoch: 34, Loss: 0.988116443157196\n",
      "Epoch: 35, Loss: 1.2821574211120605\n",
      "Epoch: 36, Loss: 0.971234917640686\n",
      "Epoch: 37, Loss: 1.1392812728881836\n",
      "Epoch: 38, Loss: 0.9306536912918091\n",
      "Epoch: 39, Loss: 0.9104565978050232\n",
      "Epoch: 40, Loss: 1.1746348142623901\n",
      "Epoch: 41, Loss: 1.0457967519760132\n",
      "Epoch: 42, Loss: 0.8315081596374512\n",
      "Epoch: 43, Loss: 1.0019376277923584\n",
      "Epoch: 44, Loss: 0.9790028929710388\n",
      "Epoch: 45, Loss: 1.091125249862671\n",
      "Epoch: 46, Loss: 0.964337944984436\n",
      "Epoch: 47, Loss: 1.095865249633789\n",
      "Epoch: 48, Loss: 1.0367493629455566\n",
      "Epoch: 49, Loss: 1.0102300643920898\n",
      "Training done\n",
      "Accuracy: 58.22% 5822/10000\n"
     ]
    }
   ],
   "source": [
    "global epochs\n",
    "epochs = 50\n",
    "\n",
    "model = ModelDropout()\n",
    "model = basic_training(model)\n",
    "test_model(model)\n",
    "\n",
    "model = ModelConvolutionalLayers()\n",
    "model = basic_training(model)\n",
    "test_model(model)\n",
    "epochs = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще такая проблема возникает при переобучении, поэтому в теории, надо взять и подождать много эпох"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забавно, что 20 эпох достаточно для всего этого..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different activation funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different weigt initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learninig rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
