{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some preparations before we begin (or begging...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset CIFAR10\n",
       "     Number of datapoints: 50000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " <torch.utils.data.dataloader.DataLoader at 0x28afc4e0820>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, labels = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        images.append(item[0])\n",
    "        labels.append(item[1])\n",
    "    images = np.stack(images)\n",
    "    images = torch.from_numpy(images).float()\n",
    "    labels = torch.tensor(labels)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# some config vars\n",
    "batch_size = 64 \n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "learning_rate = 0.0001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# sample data\n",
    "need_download = not os.path.exists('data')\n",
    "train = torchvision.datasets.CIFAR10(root='data', train=True, download=need_download, transform=ToTensor())\n",
    "dataset = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test = torchvision.datasets.CIFAR10(root='data', train=False, download=need_download, transform=ToTensor())\n",
    "dataset_test = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "(train, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "# simple function for training and calculating loss\n",
    "def basic_training(model, allow_print=True) -> nn.Module:\n",
    "    if allow_print:\n",
    "        print(f\"{model.__class__.__name__} is training\")\n",
    "\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch, _ in enumerate(tqdm.tqdm(range(epochs))):\n",
    "        model.train()\n",
    "        for batch in dataset:\n",
    "            data, target = batch\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            opt.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        if allow_print:\n",
    "            print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "        \n",
    "    if allow_print:\n",
    "        print(\"Training done\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function for testing\n",
    "def basic_testing(model, allow_print=True) -> float:\n",
    "    if allow_print:\n",
    "        print(f\"{model.__class__.__name__} is testing\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataset_test:\n",
    "            data, target = batch\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    if allow_print:\n",
    "        print(f\"Accuracy: {correct / len(test) * 100}%\")\n",
    "    \n",
    "    return correct / len(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with only fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseModel is training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85f7ed4800d40b5993338d09fb0035d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.6972705125808716\n",
      "Epoch: 1, Loss: 1.9705039262771606\n",
      "Epoch: 2, Loss: 1.8144596815109253\n",
      "Epoch: 3, Loss: 1.3507314920425415\n",
      "Epoch: 4, Loss: 1.3221155405044556\n",
      "Epoch: 5, Loss: 1.5546053647994995\n",
      "Epoch: 6, Loss: 1.3810145854949951\n",
      "Epoch: 7, Loss: 1.1232808828353882\n",
      "Epoch: 8, Loss: 1.701409935951233\n",
      "Epoch: 9, Loss: 1.3187580108642578\n",
      "Epoch: 10, Loss: 1.2564128637313843\n",
      "Epoch: 11, Loss: 1.3767695426940918\n",
      "Epoch: 12, Loss: 1.0384756326675415\n",
      "Epoch: 13, Loss: 1.0614036321640015\n",
      "Epoch: 14, Loss: 1.2896673679351807\n",
      "Epoch: 15, Loss: 1.6821651458740234\n",
      "Epoch: 16, Loss: 1.0048247575759888\n",
      "Epoch: 17, Loss: 1.274583101272583\n",
      "Epoch: 18, Loss: 1.8488388061523438\n",
      "Epoch: 19, Loss: 1.522212028503418\n",
      "Training done\n",
      "DenseModel is testing\n",
      "Accuracy: 49.82%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4982"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a model only with fully connected layers\n",
    "class DenseModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseModel, self).__init__()\n",
    "\n",
    "        # that piece of crap almost ruined my day\n",
    "        IMG_SIZE = 32 * 32 * 3\n",
    "\n",
    "        self.fc1 = nn.Linear(IMG_SIZE, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.selu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = DenseModel()\n",
    "# model\n",
    "model = basic_training(model)\n",
    "basic_testing(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseModel2 is training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409d40c8690448a989b1f2e989bd7cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.0359292030334473\n",
      "Epoch: 1, Loss: 1.2979050874710083\n",
      "Epoch: 2, Loss: 1.3302175998687744\n",
      "Epoch: 3, Loss: 1.0358209609985352\n",
      "Epoch: 4, Loss: 0.7818771004676819\n",
      "Epoch: 5, Loss: 0.6878566145896912\n",
      "Epoch: 6, Loss: 1.0331647396087646\n",
      "Epoch: 7, Loss: 0.2888738214969635\n",
      "Epoch: 8, Loss: 0.2849367558956146\n",
      "Epoch: 9, Loss: 0.6591193079948425\n",
      "Epoch: 10, Loss: 0.1849045306444168\n",
      "Epoch: 11, Loss: 0.5032113194465637\n",
      "Epoch: 12, Loss: 0.5448060035705566\n",
      "Epoch: 13, Loss: 0.13271263241767883\n",
      "Epoch: 14, Loss: 0.4024338126182556\n",
      "Epoch: 15, Loss: 0.4045252501964569\n",
      "Epoch: 16, Loss: 0.0171759482473135\n",
      "Epoch: 17, Loss: 0.015329532325267792\n",
      "Epoch: 18, Loss: 0.06224741041660309\n",
      "Epoch: 19, Loss: 0.047683920711278915\n",
      "Training done\n",
      "Accuracy: 65.49% 6549/10000\n"
     ]
    }
   ],
   "source": [
    "class DenseModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, (3, 3)),\n",
    "            nn.SELU(),\n",
    "            nn.Conv2d(32, 64, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, (3,3)),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*(32-6)*(32-6), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(64, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = DenseModel2()\n",
    "basic_training(model)\n",
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestModel is training\n",
      "Epoch: 0, Loss: 1.812021255493164\n",
      "Epoch: 1, Loss: 1.6520737409591675\n",
      "Epoch: 2, Loss: 1.5422548055648804\n",
      "Epoch: 3, Loss: 1.4548585414886475\n",
      "Epoch: 4, Loss: 1.411234736442566\n",
      "Epoch: 5, Loss: 1.3604387044906616\n",
      "Epoch: 6, Loss: 1.3752096891403198\n",
      "Epoch: 7, Loss: 1.2885619401931763\n",
      "Epoch: 8, Loss: 1.3203836679458618\n",
      "Epoch: 9, Loss: 1.2560139894485474\n",
      "Training done\n",
      "Accuracy: 54.69% 5469/10000\n"
     ]
    }
   ],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, (3, 3)),\n",
    "            nn.SELU(),\n",
    "            nn.Conv2d(32, 64, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, (3,3)),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*(32-6)*(32-6), 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = TestModel()\n",
    "basic_training(model)\n",
    "test_model(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelConvolutionalLayers is training\n",
      "Epoch: 0, Loss: 2.232653856277466\n",
      "Epoch: 1, Loss: 1.9715029001235962\n",
      "Epoch: 2, Loss: 1.7839516401290894\n",
      "Epoch: 3, Loss: 1.688223123550415\n",
      "Epoch: 4, Loss: 1.6988224983215332\n",
      "Epoch: 5, Loss: 1.6335655450820923\n",
      "Epoch: 6, Loss: 1.5986485481262207\n",
      "Epoch: 7, Loss: 1.5196000337600708\n",
      "Epoch: 8, Loss: 1.5179378986358643\n",
      "Epoch: 9, Loss: 1.4245572090148926\n",
      "Training done\n",
      "Accuracy: 47.05% 4705/10000\n"
     ]
    }
   ],
   "source": [
    "# adding convolutional layers to the model\n",
    "class ModelConvolutionalLayers(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelConvolutionalLayers, self).__init__()\n",
    "\n",
    "        # if I write it with my hands, it doen't work, but when whappening in sequential, it works\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Linear(4 * 4 * 128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "model = ModelConvolutionalLayers()\n",
    "basic_training(model)\n",
    "test_model(model)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing different number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelSmallAmountLayers is training\n",
      "accuracy of model with only 1 layer\n",
      "Accuracy: 28.84% 2884/10000\n",
      "ModelFullyConnected is training\n",
      "accuracy of model with fully connected layers\n",
      "Accuracy: 33.62% 3362/10000\n"
     ]
    }
   ],
   "source": [
    "# model with only 1 layer\n",
    "class ModelSmallAmountLayers(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelSmallAmountLayers, self).__init__()\n",
    "\n",
    "        self.fc = nn.Linear(32 * 32 * 3, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\"\"\"\n",
    "model = ModelSmallAmountLayers()\n",
    "print(\"ModelSmallAmountLayers is training\")\n",
    "basic_training(model, allow_print=False)\n",
    "print(\"accuracy of model with only 1 layer\")\n",
    "test_model(model)\n",
    "\n",
    "model = ModelFullyConnected()\n",
    "print(\"ModelFullyConnected is training\")\n",
    "basic_training(model, allow_print=False)\n",
    "print(\"accuracy of model with fully connected layers\")\n",
    "test_model(model)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretend that ModelConvolutionalLayers in model with big amount of layers and compare them together\n",
    "as we can see from the output the model with only 1 layer is shifting much more than the model with 4 layers\n",
    "also we can see that the accuracy of such model is lower\n",
    "\n",
    "to be shorter, the more layers neural network has, the more complex objects it can detect, but the time (or resurses) for it's \n",
    "training would be increased"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelDropout is training\n",
      "Epoch: 0, Loss: 2.199138879776001\n",
      "Epoch: 1, Loss: 2.0977420806884766\n",
      "Epoch: 2, Loss: 1.4756028652191162\n",
      "Epoch: 3, Loss: 1.3236998319625854\n",
      "Epoch: 4, Loss: 2.085686445236206\n",
      "Epoch: 5, Loss: 1.5807256698608398\n",
      "Epoch: 6, Loss: 1.7575302124023438\n",
      "Epoch: 7, Loss: 1.5117683410644531\n",
      "Epoch: 8, Loss: 1.4893335103988647\n",
      "Epoch: 9, Loss: 1.7689285278320312\n",
      "Epoch: 10, Loss: 1.8285218477249146\n",
      "Epoch: 11, Loss: 1.6035689115524292\n",
      "Epoch: 12, Loss: 1.658751368522644\n",
      "Epoch: 13, Loss: 1.3808714151382446\n",
      "Epoch: 14, Loss: 1.8599021434783936\n",
      "Epoch: 15, Loss: 1.5263110399246216\n",
      "Epoch: 16, Loss: 1.829563856124878\n",
      "Epoch: 17, Loss: 1.935354471206665\n",
      "Epoch: 18, Loss: 1.7004787921905518\n",
      "Epoch: 19, Loss: 1.7640712261199951\n",
      "Training done\n",
      "Accuracy with dropout\n",
      "Accuracy: 57.07% 5707/10000\n",
      "ModelConvolutionalLayers is training\n",
      "Epoch: 0, Loss: 1.6173450946807861\n",
      "Epoch: 1, Loss: 1.3811346292495728\n",
      "Epoch: 2, Loss: 1.358305811882019\n",
      "Epoch: 3, Loss: 1.3055436611175537\n",
      "Epoch: 4, Loss: 1.3613412380218506\n",
      "Epoch: 5, Loss: 1.2089289426803589\n",
      "Epoch: 6, Loss: 1.337955355644226\n",
      "Epoch: 7, Loss: 1.2206746339797974\n",
      "Epoch: 8, Loss: 1.1535431146621704\n",
      "Epoch: 9, Loss: 1.2775297164916992\n",
      "Epoch: 10, Loss: 1.2461860179901123\n",
      "Epoch: 11, Loss: 1.1193068027496338\n",
      "Epoch: 12, Loss: 1.0678062438964844\n",
      "Epoch: 13, Loss: 1.3213382959365845\n",
      "Epoch: 14, Loss: 1.085822582244873\n",
      "Epoch: 15, Loss: 1.1566519737243652\n",
      "Epoch: 16, Loss: 1.1013792753219604\n",
      "Epoch: 17, Loss: 1.3299962282180786\n",
      "Epoch: 18, Loss: 1.1872140169143677\n",
      "Epoch: 19, Loss: 1.1281921863555908\n",
      "Training done\n",
      "Accuracy: 60.32% 6032/10000\n"
     ]
    }
   ],
   "source": [
    "# adding dropout layer\n",
    "\n",
    "global epochs\n",
    "epochs = 20\n",
    "\n",
    "class ModelDropout(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ModelDropout, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4 * 4 * 128, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "        \n",
    "\n",
    "model = ModelDropout()\n",
    "model = basic_training(model)\n",
    "print(\"Accuracy with dropout\")\n",
    "test_model(model)\n",
    "\n",
    "model = ModelConvolutionalLayers()\n",
    "model = basic_training(model)\n",
    "test_model(model)\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelDropout is training\n",
      "Epoch: 0, Loss: 3.0776095390319824\n",
      "Epoch: 1, Loss: 2.9820263385772705\n",
      "Epoch: 2, Loss: 2.7211365699768066\n",
      "Epoch: 3, Loss: 2.8907506465911865\n",
      "Epoch: 4, Loss: 2.7787039279937744\n",
      "Epoch: 5, Loss: 2.4318625926971436\n",
      "Epoch: 6, Loss: 2.7590668201446533\n",
      "Epoch: 7, Loss: 2.548741340637207\n",
      "Epoch: 8, Loss: 2.252854824066162\n",
      "Epoch: 9, Loss: 2.676725387573242\n",
      "Epoch: 10, Loss: 2.727212429046631\n",
      "Epoch: 11, Loss: 2.5998783111572266\n",
      "Epoch: 12, Loss: 2.324941873550415\n",
      "Epoch: 13, Loss: 2.4985804557800293\n",
      "Epoch: 14, Loss: 2.946016788482666\n",
      "Epoch: 15, Loss: 2.466244697570801\n",
      "Epoch: 16, Loss: 2.595196485519409\n",
      "Epoch: 17, Loss: 2.03120493888855\n",
      "Epoch: 18, Loss: 1.7425264120101929\n",
      "Epoch: 19, Loss: 1.8041839599609375\n",
      "Epoch: 20, Loss: 2.0775558948516846\n",
      "Epoch: 21, Loss: 1.7552191019058228\n",
      "Epoch: 22, Loss: 1.8387318849563599\n",
      "Epoch: 23, Loss: 1.946933388710022\n",
      "Epoch: 24, Loss: 2.024894952774048\n",
      "Epoch: 25, Loss: 2.22885799407959\n",
      "Epoch: 26, Loss: 2.2260210514068604\n",
      "Epoch: 27, Loss: 2.0261049270629883\n",
      "Epoch: 28, Loss: 2.0732178688049316\n",
      "Epoch: 29, Loss: 2.0702831745147705\n",
      "Epoch: 30, Loss: 2.1311779022216797\n",
      "Epoch: 31, Loss: 1.8353396654129028\n",
      "Epoch: 32, Loss: 2.0914411544799805\n",
      "Epoch: 33, Loss: 1.8847291469573975\n",
      "Epoch: 34, Loss: 1.4798479080200195\n",
      "Epoch: 35, Loss: 2.2574241161346436\n",
      "Epoch: 36, Loss: 1.9625509977340698\n",
      "Epoch: 37, Loss: 2.28364634513855\n",
      "Epoch: 38, Loss: 1.7791956663131714\n",
      "Epoch: 39, Loss: 2.2341179847717285\n",
      "Epoch: 40, Loss: 2.0886054039001465\n",
      "Epoch: 41, Loss: 1.7272448539733887\n",
      "Epoch: 42, Loss: 1.9263228178024292\n",
      "Epoch: 43, Loss: 1.9017826318740845\n",
      "Epoch: 44, Loss: 1.9753737449645996\n",
      "Epoch: 45, Loss: 1.8122402429580688\n",
      "Epoch: 46, Loss: 1.9410486221313477\n",
      "Epoch: 47, Loss: 1.9307715892791748\n",
      "Epoch: 48, Loss: 2.0618348121643066\n",
      "Epoch: 49, Loss: 1.6747245788574219\n",
      "Training done\n",
      "Accuracy: 51.76% 5176/10000\n",
      "ModelConvolutionalLayers is training\n",
      "Epoch: 0, Loss: 1.3931066989898682\n",
      "Epoch: 1, Loss: 1.3455090522766113\n",
      "Epoch: 2, Loss: 1.1239718198776245\n",
      "Epoch: 3, Loss: 1.3010238409042358\n",
      "Epoch: 4, Loss: 1.3247694969177246\n",
      "Epoch: 5, Loss: 1.3513169288635254\n",
      "Epoch: 6, Loss: 1.0996323823928833\n",
      "Epoch: 7, Loss: 1.0354151725769043\n",
      "Epoch: 8, Loss: 0.9224212169647217\n",
      "Epoch: 9, Loss: 1.2624529600143433\n",
      "Epoch: 10, Loss: 1.2609840631484985\n",
      "Epoch: 11, Loss: 1.5207371711730957\n",
      "Epoch: 12, Loss: 1.0999544858932495\n",
      "Epoch: 13, Loss: 1.1310580968856812\n",
      "Epoch: 14, Loss: 1.114914059638977\n",
      "Epoch: 15, Loss: 1.020563006401062\n",
      "Epoch: 16, Loss: 0.9555630683898926\n",
      "Epoch: 17, Loss: 1.1422063112258911\n",
      "Epoch: 18, Loss: 1.1578028202056885\n",
      "Epoch: 19, Loss: 1.248921513557434\n",
      "Epoch: 20, Loss: 1.2640652656555176\n",
      "Epoch: 21, Loss: 0.9388573169708252\n",
      "Epoch: 22, Loss: 1.2153065204620361\n",
      "Epoch: 23, Loss: 1.215019702911377\n",
      "Epoch: 24, Loss: 1.5407359600067139\n",
      "Epoch: 25, Loss: 1.1280406713485718\n",
      "Epoch: 26, Loss: 1.1626838445663452\n",
      "Epoch: 27, Loss: 1.1189197301864624\n",
      "Epoch: 28, Loss: 1.1800304651260376\n",
      "Epoch: 29, Loss: 1.0728883743286133\n",
      "Epoch: 30, Loss: 1.0649189949035645\n",
      "Epoch: 31, Loss: 1.2566288709640503\n",
      "Epoch: 32, Loss: 1.0168391466140747\n",
      "Epoch: 33, Loss: 1.0182762145996094\n",
      "Epoch: 34, Loss: 0.988116443157196\n",
      "Epoch: 35, Loss: 1.2821574211120605\n",
      "Epoch: 36, Loss: 0.971234917640686\n",
      "Epoch: 37, Loss: 1.1392812728881836\n",
      "Epoch: 38, Loss: 0.9306536912918091\n",
      "Epoch: 39, Loss: 0.9104565978050232\n",
      "Epoch: 40, Loss: 1.1746348142623901\n",
      "Epoch: 41, Loss: 1.0457967519760132\n",
      "Epoch: 42, Loss: 0.8315081596374512\n",
      "Epoch: 43, Loss: 1.0019376277923584\n",
      "Epoch: 44, Loss: 0.9790028929710388\n",
      "Epoch: 45, Loss: 1.091125249862671\n",
      "Epoch: 46, Loss: 0.964337944984436\n",
      "Epoch: 47, Loss: 1.095865249633789\n",
      "Epoch: 48, Loss: 1.0367493629455566\n",
      "Epoch: 49, Loss: 1.0102300643920898\n",
      "Training done\n",
      "Accuracy: 58.22% 5822/10000\n"
     ]
    }
   ],
   "source": [
    "global epochs\n",
    "epochs = 50\n",
    "\n",
    "model = ModelDropout()\n",
    "model = basic_training(model)\n",
    "test_model(model)\n",
    "\n",
    "model = ModelConvolutionalLayers()\n",
    "model = basic_training(model)\n",
    "test_model(model)\n",
    "epochs = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще такая проблема возникает при переобучении, поэтому в теории, надо взять и подождать много эпох"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забавно, что 20 эпох достаточно для всего этого..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different activation funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different weigt initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learninig rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
